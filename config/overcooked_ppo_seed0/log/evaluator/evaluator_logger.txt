[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0000, current episode: 1
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0000, current episode: 2
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0000, current episode: 3
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0000, current episode: 4
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0000, current episode: 5
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0000, current episode: 6
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0000, current episode: 7
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0000, current episode: 8
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 0.0000, current episode: 9
[2023-11-30 23:57:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 0.0000, current episode: 10
[2023-11-30 23:57:53][interaction_serial_evaluator.py:285][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 10.000000     | 4000.000000   |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 400.000000              | 1.572042      | 2544.461685         | 6.361154             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 0.000000    | 0.000000   | 0.000000   | 0.000000   |
+-------+-------------+------------+------------+------------+
+-------+------------------------------------------------------------------------+
| Name  | eval_episode_return                                                    |
+-------+------------------------------------------------------------------------+
| Value | [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]] |
+-------+------------------------------------------------------------------------+

